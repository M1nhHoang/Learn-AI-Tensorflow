{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4512731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "# tải về dữ liệu tiếng Việt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e71302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đường dẫn tới file chứa dữ liệu câu hỏi và câu trả lời\n",
    "data_path = './chatDataSet.txt'\n",
    "\n",
    "# đọc dữ liệu từ file\n",
    "with open(data_path, 'r', encoding='utf8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "# xử lý dữ liệu\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b732fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tách câu thành từng từ và đưa về dạng nguyên mẫu\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().strip()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "# tạo từ điển chứa các từ trong dữ liệu\n",
    "word_dict = {}\n",
    "for line in lines:\n",
    "    words = preprocess_text(line)\n",
    "    for word in words:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d8d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo câu hỏi và câu trả lời dưới dạng chuỗi số\n",
    "question_seqs = []\n",
    "answer_seqs = []\n",
    "\n",
    "for line in lines:\n",
    "    if line:\n",
    "        line = line.strip()\n",
    "        parts = line.split(\":\")\n",
    "        if len(parts) == 2:\n",
    "            question = preprocess_text(parts[0])\n",
    "            answer = preprocess_text(parts[1])\n",
    "            question_seqs.append([word_dict[q] for q in question])\n",
    "            answer_seqs.append([word_dict[a] for a in answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bcb03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuyển đổi định dạng chuỗi số sang ma trận\n",
    "maxlen = 50\n",
    "question_data = np.zeros((len(question_seqs), maxlen), dtype=np.int32)\n",
    "answer_data = np.zeros((len(answer_seqs), maxlen), dtype=np.int32)\n",
    "\n",
    "for i, seq in enumerate(question_seqs):\n",
    "    if seq:\n",
    "        question_data[i, -len(seq):] = np.array(seq)[:maxlen]\n",
    "\n",
    "for i, seq in enumerate(answer_seqs):\n",
    "    if seq:\n",
    "        answer_data[i, -len(seq):] = np.array(seq)[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d4c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12859, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78882592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12859, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc3bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_dict)\n",
    "embedding_dim = 128\n",
    "lstm_units = 256\n",
    "embedding_dim = 50\n",
    "from keras.layers import TimeDistributed, Bidirectional\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=maxlen),\n",
    "        LSTM(lstm_units, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc44506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 200)      1000200     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 50, 200)      1000200     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 200),    320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50, 5001)     1005201     ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,647,201\n",
      "Trainable params: 3,647,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a563785c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'int\\\\\\'>\"})\\'})'}), <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25160/3110227406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     history = model.fit([question_seqs, answer_seqs], np.expand_dims(answer_seqs, -1),\n\u001b[0m\u001b[0;32m      7\u001b[0m                         batch_size=batch_size, epochs=epochs)\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1082\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[0;32m   1083\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'int\\\\\\'>\"})\\'})'}), <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# huấn luyện mô hình\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(question_data, tf.keras.utils.to_categorical(answer_data, num_classes=vocab_size),\n",
    "                        batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c939cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_loss'], c = 'coral', label = 'validation loss line')\n",
    "plt.plot(history.history['loss'], c = 'blue', label = 'train loss line')\n",
    "legend = plt.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc799d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(r'./botChatv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab04e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def predict_answer(question):\n",
    "    # tiền xử lý câu hỏi\n",
    "    question = preprocess_text(question)\n",
    "    seq = [word_dict[word] for word in question]\n",
    "    seq = pad_sequences([seq], maxlen=maxlen)\n",
    "    print(question)\n",
    "    # dự đoán câu trả lời\n",
    "    prediction = model.predict(seq)\n",
    "    prediction = prediction[0][-len(question):]\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "    # chuyển đổi lại sang dạng văn bản\n",
    "    print(prediction)\n",
    "    rev_word_dict = {v: k for k, v in word_dict.items()}\n",
    "    answer = [rev_word_dict[idx] for idx in prediction]\n",
    "    answer = ' '.join(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57208fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['khôn']\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "[0]\n",
      "ngon\n"
     ]
    }
   ],
   "source": [
    "question = 'khôn'\n",
    "print(predict_answer(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78495241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
