{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4512731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "# tải về dữ liệu tiếng Việt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e71302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đường dẫn tới file chứa dữ liệu câu hỏi và câu trả lời\n",
    "data_path = './chatDataSet.txt'\n",
    "\n",
    "# đọc dữ liệu từ file\n",
    "with open(data_path, 'r', encoding='utf8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "# xử lý dữ liệu\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b732fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tách câu thành từng từ và đưa về dạng nguyên mẫu\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().strip()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "# tạo từ điển chứa các từ trong dữ liệu\n",
    "word_dict = {}\n",
    "for line in lines:\n",
    "    words = preprocess_text(line)\n",
    "    for word in words:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d8d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo câu hỏi và câu trả lời dưới dạng chuỗi số\n",
    "question_seqs = []\n",
    "answer_seqs = []\n",
    "\n",
    "for line in lines:\n",
    "    if line:\n",
    "        line = line.strip()\n",
    "        parts = line.split(\":\")\n",
    "        if len(parts) == 2:\n",
    "            question = preprocess_text(parts[0])\n",
    "            answer = preprocess_text(parts[1])\n",
    "            question_seqs.append([word_dict[q] for q in question])\n",
    "            answer_seqs.append([word_dict[a] for a in answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bcb03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuyển đổi định dạng chuỗi số sang ma trận\n",
    "maxlen = 50\n",
    "question_data = np.zeros((len(question_seqs), maxlen), dtype=np.int32)\n",
    "answer_data = np.zeros((len(answer_seqs), maxlen), dtype=np.int32)\n",
    "\n",
    "for i, seq in enumerate(question_seqs):\n",
    "    if seq:\n",
    "        question_data[i, -len(seq):] = np.array(seq)[:maxlen]\n",
    "\n",
    "for i, seq in enumerate(answer_seqs):\n",
    "    if seq:\n",
    "        answer_data[i, -len(seq):] = np.array(seq)[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d4c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12859, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78882592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12859, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc3bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_dict)\n",
    "embedding_dim = 128\n",
    "lstm_units = 256\n",
    "embedding_dim = 50\n",
    "from keras.layers import TimeDistributed, Bidirectional\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=maxlen),\n",
    "        LSTM(lstm_units, return_sequences=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc44506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 50)            250000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50, 256)           314368    \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 50, 5000)         1285000   \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,849,368\n",
      "Trainable params: 1,849,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "161/161 [==============================] - 143s 877ms/step - loss: 1.8401 - accuracy: 0.8975 - val_loss: 1.1318 - val_accuracy: 0.9018\n",
      "Epoch 2/50\n",
      "161/161 [==============================] - 139s 860ms/step - loss: 1.0236 - accuracy: 0.9032 - val_loss: 0.9755 - val_accuracy: 0.9018\n",
      "Epoch 3/50\n",
      "161/161 [==============================] - 139s 866ms/step - loss: 0.8844 - accuracy: 0.9032 - val_loss: 0.8714 - val_accuracy: 0.9018\n",
      "Epoch 4/50\n",
      "161/161 [==============================] - 140s 872ms/step - loss: 0.8334 - accuracy: 0.9032 - val_loss: 0.8638 - val_accuracy: 0.9018\n",
      "Epoch 5/50\n",
      "161/161 [==============================] - 139s 865ms/step - loss: 0.8226 - accuracy: 0.9032 - val_loss: 0.8486 - val_accuracy: 0.9021\n",
      "Epoch 6/50\n",
      "161/161 [==============================] - 136s 847ms/step - loss: 0.8150 - accuracy: 0.9032 - val_loss: 0.8365 - val_accuracy: 0.9021\n",
      "Epoch 7/50\n",
      "161/161 [==============================] - 142s 880ms/step - loss: 0.8102 - accuracy: 0.9032 - val_loss: 0.8410 - val_accuracy: 0.9021\n",
      "Epoch 8/50\n",
      " 38/161 [======>.......................] - ETA: 1:37 - loss: 0.8088 - accuracy: 0.9021"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# huấn luyện mô hình\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(question_data, tf.keras.utils.to_categorical(answer_data, num_classes=vocab_size),\n",
    "                        batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c939cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_loss'], c = 'coral', label = 'validation loss line')\n",
    "plt.plot(history.history['loss'], c = 'blue', label = 'train loss line')\n",
    "legend = plt.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc799d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(r'./botChatv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab04e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def predict_answer(question):\n",
    "    # tiền xử lý câu hỏi\n",
    "    question = preprocess_text(question)\n",
    "    seq = [word_dict[word] for word in question]\n",
    "    seq = pad_sequences([seq], maxlen=maxlen)\n",
    "    print(question)\n",
    "    # dự đoán câu trả lời\n",
    "    prediction = model.predict(seq)\n",
    "    prediction = prediction[0][-len(question):]\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "    # chuyển đổi lại sang dạng văn bản\n",
    "    print(prediction)\n",
    "    rev_word_dict = {v: k for k, v in word_dict.items()}\n",
    "    answer = [rev_word_dict[idx] for idx in prediction]\n",
    "    answer = ' '.join(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57208fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi']\n",
      "1/1 [==============================] - 1s 693ms/step\n",
      "[0]\n",
      "ngon\n"
     ]
    }
   ],
   "source": [
    "question = 'hi'\n",
    "print(predict_answer(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78495241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
